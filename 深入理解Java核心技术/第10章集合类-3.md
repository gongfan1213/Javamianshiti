### 10.9 同步容器的所有操作一定是线程安全的吗

为了方便编写线程安全的程序，Java提供了一些线程安全类和并发工具，比如同步容器、并发容器和阻塞队列等。

最常见的同步容器就是Vector和HashTable了，那么同步容器的所有操作都是线程安全的吗？

本节深入分析这个很容易被忽略的问题。
#### 1. Java中的同步容器
在Java中，同步容器主要包括2类：
- Vector、Stack和HashTable。
- Collections类中提供的静态工厂方法创建的类。
本节以相对简单的Vector为例，Vector中几个重要方法的源码如下：
```java
public synchronized boolean add(E e) {
    modCount++;
    ensureCapacityHelper(elementCount + 1);
    elementData[elementCount++] = e;
    return true;
}
public synchronized E remove(int index) {
    modCount++;
    if (index >= elementCount)
        throw new ArrayIndexOutOfBoundsException(index);
    E oldValue = elementData(index);
    int numMoved = elementCount - index - 1;
    if (numMoved > 0)
        System.arraycopy(elementData, index+1, elementData, index, numMoved);
    elementData[--elementCount] = null; // Let gc do its work
    return oldValue;
}
public synchronized E get(int index) {
    if (index >= elementCount)
        throw new ArrayIndexOutOfBoundsException(index);
    return elementData(index);
}
```

可以看到，Vector这样的同步容器的所有公有方法都被synchronized修饰了，也就是说，我们可以在多线程场景中放心地单独使用这些方法，因为这些方法本身的确是线程安全的。

请注意上面这句话中有一个比较关键的词：单独。

虽然同步容器的所有方法都加了锁，但是对这些容器的复合操作，无法保证其线程安全性，需要客户端通过主动加锁来保证。

简单举一个例子，我们定义如下删除Vector中最后一个元素的方法：

```java
public Object deleteLast(Vector v){
    int lastIndex = v.size()-1;
    v.remove(lastIndex);
}
```
上面这个方法是一个复合方法，包括size()和remove()，乍一看好像并没有什么问题，无论size()方法还是remove()方法都是线程安全的，那么整个deleteLast方法应该也是线程安全的。
但是，在多线程调用该方法的过程中，remove()方法有可能抛出ArrayIndexOutOfBounds-Exception异常。remove()方法的源码如下：
```
Exception in thread "Thread-1" java.lang.ArrayIndexOutOfBoundsException: Array index
out of range: 879
at java.util.Vector.remove(Vector.java:834)
at com.hollis.Test.deleteLast(EncodeTest.java:40)
at com.hollis.Test$2.run(EncodeTest.java:28)
at java.lang.Thread.run(Thread.java:748)
```
当index≥elementCount时，会抛出ArrayIndexOutOfBoundsException异常，也就是说，当前索引值不再有效时，将抛出这个异常。

removeLast方法有可能被多个线程同时执行，线程2通过index()获得的索引值为10，在通过remove()删除该索引位置的元素之前，线程1把该索引位置的值删除了，这时在执行线程1时便会抛出异常，如图10 - 6所示。

![image](https://github.com/user-attachments/assets/236ca7ac-0e3d-4c5e-a07c-ababf2a68069)


为了避免出现类似问题，可以尝试加锁：
```java
public void deleteLast() {
    synchronized (v) {
        int index = v.size() - 1;
        v.remove(index);
    }
}
```

在deleteLast中对v进行加锁，即可保证同一时刻不会有其他线程删除v中的元素。

另外，以下代码被多线程执行时，也要特别注意：
```java
for (int i = 0; i < v.size(); i++) {
    v.remove(i);
}
```
由于不同线程在同一时间操作同一个Vector，其中包括删除操作，那么就有可能发生线程安全问题。所以，在使用同步容器时，如果涉及多个线程同时执行删除操作，就要考虑是否需要加锁。
#### 2. 同步容器的问题

前面说过，同步容器可以保证单个操作的线程安全性，但无法保证复合操作的线程安全，遇到这种情况时，必须通过主动加锁的方式来实现线程安全。

除此之外，由于同步容器对其所有方法都加了锁，导致多个线程访问同一个容器时，只能按顺序访问，即使是不同的操作，也要排队，如get和add要排队执行，这就大大降低了容器的并发能力。

#### 3. 并发容器

针对同步容器存在的并发度低的问题，从Java5开始，在java.util.concurrent包下提供了大量支持高效并发访问的集合类，我们称之为并发容器，如图10 - 7所示。
- ConcurrentHashMap
- ConcurrentLinkedDeque
- ConcurrentLinkedQueue
- ConcurrentMap
- ConcurrentNavigableMap
- ConcurrentSkipListMap
- ConcurrentSkipListSet
- CopyOnWriteArrayList
- CopyOnWriteArraySet
- CountDownLatch

针对同步容器的复合操作的问题，一般在Map中发生的比较多，所以在ConcurrentHashMap中增加了对常用复合操作的支持，比如使用putIfAbsent()实现 “若没有则添加” 的功能，使用replace()实现替换的功能。这2个操作都是原子操作，可以保证线程安全。
### 小结

本节介绍了同步容器和并发容器。

同步容器是通过加锁实现线程安全的，并且只能保证单独的操作是线程安全的，无法保证复合操作的线程安全性。同步容器的读和写操作之间互相阻塞。

并发容器是Java 5中提供的，主要用来代替同步容器。并发容器有更好的并发能力，而且其中的ConcurrentHashMap定义了线程安全的复合操作。

在多线程场景中，如果使用并发容器，那么一定要注意复合操作的线程安全问题，必要时要主动加锁。

在并发场景中，建议直接使用java.util.concurrent包中提供的容器类，在需要复合操作时，建议使用有些容器自身提供的复合方法。

### 10.10 HashMap的数据结构

了解了HashMap、HashTable、ConcurrentHashMap等的用法和区别后，接下来针对HashMap做一系列的介绍，在介绍这些知识点之前，先介绍HashMap中的一些概念。首先，我们要知道到底什么是Hash。

当我们向一个HashMap中 “put” 一个元素时，就需要通过一定的算法计算出应该把它放到哪个 “桶” 中，这个过程就叫作Hash，对应的就是HashMap中的hash()方法。

#### 1. Hash

Hash一般翻译为散列，也有直接音译为哈希的，就是把任意长度的输入通过散列算法转换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能通过散列值来唯一地确定输入值。简单地说，Hash就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。


所有散列函数都有如下一个基本特性：如果根据同一散列函数计算出的散列值不同，那么输入值肯定也不同。但是，如果根据同一散列函数计算出的散列值相同，那么输入值不一定相同。

两个不同的输入值，根据同一散列函数计算出的散列值相同的现象叫作碰撞。

常见的Hash算法以下几个：

- 直接定址法：直接以关键字k或者k加上某个常数（k + c）作为Hash地址。

- 数字分析法：提取关键字中取值比较均匀的数字作为Hash地址。

- 除留余数法：用关键字k除以某个不大于Hash表长度m的数p，将所得余数作为Hash表地址。

- 分段叠加法：按照Hash表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短，然后将这几部分相加，舍弃最高进位后的结果就是该关键字的Hash地址。

- 平方取中法：如果关键字各个部分分布都不均匀，则可以先求出它的平方值，然后按照需求取中间的几位作为Hash地址。

- 伪随机数法：采用一个伪随机数当作Hash函数。

衡量一个Hash算法的重要指标就是发生碰撞的概率，以及发生碰撞的解决方案。任何Hash函数基本都无法彻底避免碰撞，常见的解决碰撞的方法有以下几种：

- 开放定址法：一旦发生了碰撞，就去寻找下一个空的散列地址，只要散列表足够大，总能找到空的散列地址，并将元素存人。

- 链地址法：将Hash表的每个单元作为链表的头节点，所有Hash地址为i的元素构成一个同义词链表，即发生碰撞时就把该关键字链接在以该单元为头节点的链表的尾部。 

- 再Hash法：当Hash地址发生碰撞时使用其他函数计算另一个Hash函数地址，直到不再产生冲突为止。

- 建立公共溢出区：将Hash表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表。

#### 2. HashMap的数据结构

在Java中，有两种比较简单的数据结构：数组和链表。数组的特点是寻址容易，插入和删除困难；而链表的特点是寻址困难，插入和删除容易。前面提到过，一种常用的解决Hash函数碰撞的办法叫作链地址法，其实就是将数组和链表组合在一起，发挥了两者的优势，我们可以将其理解为链表的数组，如图10 - 8所示。

![image](https://github.com/user-attachments/assets/8a091129-e15a-4371-bd73-f9f26be4219f)


在图10 - 8中，左边很明显是一个数组，数组中的每个成员是一个链表。该数据结构所容纳的所有元素均包含一个指针，用于元素间的链接。我们根据元素的自身特征把元素分配到不同的链表中，反过来我们可以通过这些特征找到正确的链表，再从链表中找出正确的元素。其中，根据元素特征计算元素数组下标的方法就是Hash算法。 


### 10.11 HashMap的size和capacity有什么区别

了解HashMap的数据结构之后，下面介绍HashMap中的一些概念，如容量、负载因子等。本节的内容基于JDK1.8.0_73。

HashMap中主要的成员变量如图10 - 9所示。


![image](https://github.com/user-attachments/assets/307dac8f-5545-448f-9fd3-64ebec2b158b)


| inherited members (id=72) | Anonymous Classes (id=1) | Lambdas (id=1) |
| --- | --- | --- |
| DEFAULT_INITIAL_CAPACITY: int = 1 << 4 |  |  |
| DEFAULT_LOAD_FACTOR: float = 0.75f |  |  |
| entrySet: Set<Map.Entry<K,V>> |  |  |
| loadFactor: float |  |  |
| MAXIMUM_CAPACITY: int = 1 << 30 |  |  |
| MIN_TREEIFY_CAPACITY: int = 64 |  |  |
| modCount: int |  |  |
| serialVersionUID: long = 362498820763181265L |  |  |
| size: int |  |  |
| table: Node<K,V>[] |  |  |
| threshold: int |  |  |
| TREEIFY_THRESHOLD: int = 8 |  |  |
| UNTREEIFY_THRESHOLD: int = 6 |  |  |

首先介绍其中两个表示大小的变量：size和capacity。
- size：记录Map中K - V对的个数。
- capacity：容量，如果不指定，则默认容量是16（static final int DEFAULT_INITIAL_CAPACITY = 1 << 4 ）。

HashMap的示意图如图10 - 10所示。

![image](https://github.com/user-attachments/assets/2f86ecaa-aab1-4ac7-8518-2ee823d6bd9e)


打个比方，HashMap就是一个 “桶” ，容量（capacity）就是这个桶当前最多可以装多少元素，而元素个数（size）表示这个桶已经装了多少元素。

例如以下代码：

```java
Map<String, String> map = new HashMap<String, String>();
map.put("hollis", "hollischuang");
Class<?> mapType = map.getClass();
Method capacity = mapType.getDeclaredMethod("capacity");
capacity.setAccessible(true);
System.out.println("capacity : " + capacity.invoke(map));
Field size = mapType.getDeclaredField("size");
size.setAccessible(true);
System.out.println("size : " + size.get(map));
```
输出结果如下：
```
capacity : 16, size : 1
```
以上代码定义了一个新的HashMap，并向其中 “put” 了一个元素，然后通过反射的方式打印capacity和size，其容量是16，已经存放的元素个数是1。
### 10.12 HashMap的扩容机制

了解HashMap的capacity和size的概念之后，很多读者可能会想到一个问题，那就是HashMap的容量会不会变？什么时候变？

其实，除了初始化时会指定HashMap的容量，在扩容时，其容量也可能改变。

HashMap有扩容机制，当达到扩容条件时会进行扩容。而且HashMap在扩容的过程中不仅要对其容量进行扩充，还需要进行 “rehash” 。所以，这个过程其实是很耗时的，并且Map中的元素越多越耗时。

rehash的过程相当于对其中所有的元素重新做一遍Hash运算，重新计算元素要分配到哪个桶中。

HashMap不是一个数组链表吗？不扩容也可以无限存储元素，为什么还要扩容呢？

这其实和Hash碰撞有关。

#### 1. Hash碰撞
有很多办法可以解决Hash碰撞，其中比较常见的就是链地址法，这也是HashMap采用的方法，如图10 - 11所示。


![image](https://github.com/user-attachments/assets/281f92a1-c8ee-4033-9af1-41afa0883a65)



我们在向HashMap中 “put” 元素时，需要先将元素定位到要存储在数组中的哪条链表上，然后把这个元素 “挂” 在这个链表的后面。

当我们从HashMap中 “get” 元素时，需要定位到数组中的哪条链表上，然后逐一遍历链表中的元素，直到找到需要的元素为止。

可见，HashMap通过链表的数组这种结构解决了Hash碰撞的问题。

如果一个HashMap中的碰撞太多，那么数组的链表就会退化为链表，这时查询速度会大大降低。

所以，为了保证HashMap的读取速度，我们需要尽量保证HashMap的碰撞不要太多。

#### 2. 通过扩容避免Hash碰撞
如何能有效地避免Hash碰撞呢？
我们先反向思考一下，你认为什么情况会导致HashMap的Hash碰撞比较多？示意图如图10 - 12所示。

![image](https://github.com/user-attachments/assets/8a037c0f-e412-4dff-8924-8786f3c22ec4)




无外乎两种情况：

（1）容量太小。容量小，元素碰撞的概率就高了。

（2）Hash算法不合理。算法不合理，元素就有可能都分到同一个或几个桶中。分配不均，也会发生争抢。

所以，解决HashMap中的Hash碰撞也是从这两方面入手的。

首先在合适的时候扩大数组容量，再通过一个合适的Hash算法将元素分配到这个数组中，既可以大大减少元素碰撞的概率，也可以避免查询效率低下的问题。

### 10.13 HashMap的loadFactor和threshold



HashMap的扩容是通过resize方法实现的，下面是HashMap中的扩容方法（resize）中的一段代码：

```java

if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
        oldCap >= DEFAULT_INITIAL_CAPACITY)
    newThr = oldThr << 1; // double threshold
```
从上面的代码可以看出，扩容后的Table容量变为原来的两倍。

HashMap中定义了loadFactor和threshold两个属性：
- loadFactor：负载因子，用来衡量HashMap “满” 的程度。loadFactor的默认值为0.75f（static final float DEFAULT_LOAD_FACTOR = 0.75f ）。
- threshold：临界值，当实际K - V个数超过threshold时，HashMap会将容量扩容，threshold = 容量×负载因子。


前面我们提到，当达到扩容条件时HashMap会进行扩容，将容量扩大到原来的两倍。

这个扩容条件指的是什么呢？

HashMap的扩容条件就是当HashMap中的元素个数（size）超过临界值（threshold）时就会自动扩容。

在HashMap中，threshold = loadFactor × capacity。

对于一个默认的HashMap来说（默认容量是16），默认情况下（默认负载因子是0.75），当其size大于12（16×0.75）时就会触发扩容。

验证代码如下：
```java
Map<String, String> map = new HashMap<>();
map.put("hollis1", "hollischuang");
map.put("hollis2", "hollischuang");
map.put("hollis3", "hollischuang");
map.put("hollis4", "hollischuang");
map.put("hollis5", "hollischuang");
map.put("hollis6", "hollischuang");
map.put("hollis7", "hollischuang");
map.put("hollis8", "hollischuang");
map.put("hollis9", "hollischuang");
map.put("hollis10", "hollischuang");
map.put("hollis11", "hollischuang");
map.put("hollis12", "hollischuang");
Class<?> mapType = map.getClass();
Method capacity = mapType.getDeclaredMethod("capacity");
capacity.setAccessible(true);
System.out.println("capacity : " + capacity.invoke(map));
Field size = mapType.getDeclaredField("size");
size.setAccessible(true);
System.out.println("size : " + size.get(map));
Field threshold = mapType.getDeclaredField("threshold");
threshold.setAccessible(true);
System.out.println("threshold : " + threshold.get(map));
Field loadFactor = mapType.getDeclaredField("loadFactor");
loadFactor.setAccessible(true);
System.out.println("loadFactor : " + loadFactor.get(map));
map.put("hollis13", "hollischuang");
Method capacity = mapType.getDeclaredMethod("capacity");
capacity.setAccessible(true);
System.out.println("capacity : " + capacity.invoke(map));
Field size = mapType.getDeclaredField("size");
size.setAccessible(true);
System.out.println("size : " + size.get(map));
Field threshold = mapType.getDeclaredField("threshold");
threshold.setAccessible(true);
System.out.println("threshold : " + threshold.get(map));
Field loadFactor = mapType.getDeclaredField("loadFactor");
loadFactor.setAccessible(true);
System.out.println("loadFactor : " + loadFactor.get(map));
```
输出结果如下：
```
capacity : 16
size : 12
threshold : 12
loadFactor : 0.75
capacity : 32
size : 13
threshold : 24
loadFactor : 0.75
```

当HashMap中的元素个数达到13的时候，capacity就从16扩容到32了。

HashMap中还提供了一个支持传入initialCapacity和loadFactor两个参数的方法来初始化容量和负载因子。不过，一般不建议修改loadFactor的值。

### 10.14 为什么建议集合初始化时指定容量大小

前面介绍了很多集合类，如常见的ArrayList、TreeSet和HashMap等，这些集合类其实都有很多重载的构造函数，在这些构造函数中，有一部分是可以指定容量的。

例如，ArrayList的构造函数支持传入初始容量：

```java
/**
 * Constructs an empty list with the specified initial capacity.
 *
 * @param  initialCapacity  the initial capacity of the list
 * @throws IllegalArgumentException if the specified initial capacity
 *         is negative
 */
public ArrayList(int initialCapacity) {
    if (initialCapacity > 0) {
        this.elementData = new Object[initialCapacity];
    } else if (initialCapacity == 0) {
        this.elementData = EMPTY_ELEMENTDATA;
    } else {
        throw new IllegalArgumentException("Illegal Capacity: "+
                                           initialCapacity);
    }
}
```
HashMap的构造函数同样支持传入初始容量：
```java
/**
 * Constructs an empty {code HashMap} with the specified initial
 * capacity and the default load factor (0.75).
 *
 * @param  initialCapacity the initial capacity.
 * @throws IllegalArgumentException if the initial capacity is negative.
 */
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}
```

那么，我们要不要指定集合的初始容量呢？本节以HashMap为例进行说明。

下面分别测试在不指定初始化容量和指定初始化容量的情况下程序的性能（JDK版本为1.7.0_79），代码如下：
```java
public static void main(String[] args) {
    int aHundredMillion = 100000000;
    Map<Integer, Integer> map = new HashMap<>();
    long s1 = System.currentTimeMillis();
    for (int i = 0; i < aHundredMillion; i++) {
        map.put(i, i);
    }
    long s2 = System.currentTimeMillis();
    System.out.println("未初始化容量，耗时：" + (s2 - s1));
    Map<Integer, Integer> map1 = new HashMap<>(aHundredMillion / 2);
    long s5 = System.currentTimeMillis();
    for (int i = 0; i < aHundredMillion; i++) {
        map1.put(i, i);
    }
    long s6 = System.currentTimeMillis();
    System.out.println("初始化容量为50000000，耗时：" + (s6 - s5));
    Map<Integer, Integer> map2 = new HashMap<>(aHundredMillion);
    long s3 = System.currentTimeMillis();
    for (int i = 0; i < aHundredMillion; i++) {
        map2.put(i, i);
    }
    long s4 = System.currentTimeMillis();
    System.out.println("初始化容量为100000000，耗时 ：" + (s4 - s3));
}
```
以上代码创建了3个HashMap，分别使用默认的容量（16）、元素个数的一半（5000万）、元素个数（一亿）作为初始容量初始化HashMap，然后分别向其中 “put” 一亿个键值对。

输出结果如下：
```
未初始化容量，耗时：14419
初始化容量为50000000，耗时：11916
初始化容量为100000000，耗时 ：7984
```

由以上结果可以知道，在已知HashMap中将要存放的键值对个数的情况下，设置一个合理的初始化容量可以有效地提高性能。

如果没有设置初始容量的大小，那么随着元素的不断增加，HashMap会发生多次扩容，而HashMap的扩容机制决定了每次扩容都需要重建Hash表，这是非常影响性能的。

从上面的代码示例中，我们还发现，同样是设置初始容量，设置的数值不同也会影响性能，当我们已知HashMap中即将存放的键值对数时，容量设置成多少合适呢？

### 10.15 HashMap的初始容量设置为多少合适

当我们使用HashMap(int initialCapacity)初始化HashMap的容量时，JDK会默认帮我们计算一个相对合理的值作为初始容量。

但是，这个值看似合理，实际上并不尽然。因为HashMap在根据用户传入的capacity计算默认容量时，并没有考虑loadFactor这个因素，只是简单机械地计算出第一个大于这个数字的2的幂。 
